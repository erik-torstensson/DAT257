**Summary of week 5**

The main theme of this week has been to implement our KPIs in a more efficient and structured way. To ensure code quality to some extent, the group has constructed a review form that evaluates the request’s code. Some new features have been added to the group’s product; reducing cluster on map, added popup window on map, show the user available parkings in relevant zones. 

During Friday we held another meeting with our stakeholders, updating them on the project. We received feedback regarding valuable features to be implemented and a suggestion to conduct customer surveys.

--- 

**Customer Value and Scope**

Before this week acceptance tests were not declared beforehand. Instead it was performed in a more ad hoc way. To make sure that the code is up to standard and that all submitted code meets our criterias we have implemented a checklist that needs to be filled out when reviewing code. This will hopefully make our submitted code better.
Our velocity KPI was implemented this week along with a quality KPI. Together with our already established stress KPI, this makes up our three KPIs. In a broad sense these have worked out great and will help us perform better as a team. The KPIs are described in more detail further down.
The stress levels this week has gone up compared to last week. The majority of the group members says that it is due to increased workload in other courses/engagements. With a mean value of 6 on the scale of 1-10, we still consider the level to be healthy. 

---

**Social Contract and Effort**

Effort is being evaluated as a KPI every week now, and it has worked relatively well this first week. We have decided on having 70 points(10 for each member) to divide during a weekly sprint, as a whole week's effort. The first week we started with 68 points, which later got reduced to 66 when one task proved to be unnecessary. Out of these 66 points all were achieved but not all code got reviewed. This could be because code review and other supporting activities are not represented in the effort evaluation. We have decided to take a second look at our review habits, with a consultation with our supervisor we hope to create a better system in the future. 

---

**Design decisions and product structure**

We changed one use case, which resulted in lower the prioritization of calendar subscription, since we now think “create event” in their own calendar will meet the user needs better.

To ensure code quality, we introduced a quality KPI in terms of a checklist which we will use every time we review new pull requests. We’re not sure how good this KPI is yet, since only one pull request has been approved this week. We have some others in review, we will reflect further on this next week.

We restructured the project’s files by dividing the main script file into several script files depending on the feature such as map, calendar, and autocomplete javascript files. 

---

**Application of Scrum**

We now feel more comfortable in our routines, such as the change of scrum master, stand up meetings and our two weekly (longer meetings). 

We include our stakeholders every week, show them a prototype and receive feedback of our work. They also give advice on how to improve our agile process. This week they wanted us to do some quick user studies until next time, to get user feedback early in the development. We’ll try to reach some users, but since the circumstances of covid-19 it might not be as easy as usual.
